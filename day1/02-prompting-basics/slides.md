# 프롬프팅 기초

## 프롬프팅이란?

---

## 학습 목표

- K-shot 프롬프팅의 원리를 이해하고 적용할 수 있다
- Chain of Thought (CoT) 기법으로 복잡한 문제를 해결할 수 있다
- Self-Consistency 기법으로 답변의 신뢰도를 높일 수 있다

---

## K-shot 프롬프팅

---

### K-shot 프롬프팅이란?

LLM에게 **예시(example)**를 제공하여 원하는 출력 형식이나 패턴을 학습시키는 기법

```
Zero-shot: 예시 없이 질문만
One-shot:  예시 1개 + 질문
Few-shot:  예시 2~5개 + 질문
```

---

### Zero-shot vs Few-shot

**Zero-shot (예시 없음)**
```
입력: "happy"를 프랑스어로 번역해줘
출력: heureux (불확실한 형식)
```

**Few-shot (예시 있음)**
```
입력:
  영어: cat → 프랑스어: chat
  영어: dog → 프랑스어: chien
  영어: happy → 프랑스어: ?
출력: heureux (일관된 형식)
```

---

### K-shot 적용 시점

- 특정 출력 형식이 필요할 때
- 일관된 패턴으로 응답받고 싶을 때
- 분류, 추출, 변환 작업

---

## Chain of Thought (CoT)

---

### Chain of Thought란?

LLM에게 **단계별로 생각하도록** 유도하여 복잡한 추론 문제를 해결하는 기법

---

### CoT가 효과적인 이유

- 복잡한 문제를 작은 단계로 분해
- 중간 과정이 보이므로 검증 가능
- 수학, 논리 문제에서 정확도 크게 향상

---

### CoT 예시

**CoT 없이**
```
Q: 복잡한 수학 문제
A: 43 (바로 답, 틀릴 확률 높음)
```

**CoT 적용**
```
Q: 복잡한 수학 문제
A: 단계별로 풀어보겠습니다.
   1. 첫 번째 단계...
   2. 두 번째 단계...
   3. 최종 답: 43
```

---

### CoT 유도 방법

- "단계별로 생각해보세요"
- "Let's think step by step"
- "차근차근 풀어봅시다"

---

### CoT 적용 시점

- 수학 문제
- 논리 추론
- 복잡한 의사결정
- 코드 디버깅

---

## Self-Consistency

---

### Self-Consistency란?

같은 문제에 대해 **여러 번 추론**하고, 결과를 **종합 분석**하여 신뢰도 높은 답을 도출하는 기법

---

### Self-Consistency 작동 방식

```
문제: 스타트업 아이디어 평가

분석 1: 장점 A, B / 단점 X → 성공 가능성: 중
분석 2: 장점 A, C / 단점 Y → 성공 가능성: 상
분석 3: 장점 B, C / 단점 X, Z → 성공 가능성: 중
...

종합 분석: 공통 장점, 공통 단점, 의견이 갈린 부분 → 최종 평가
```

---

### Self-Consistency 적용 시점

- 주관적 판단이 필요한 문제
- 높은 신뢰도가 필요한 경우
- 다양한 관점이 필요한 분석

---

### Self-Consistency 트레이드오프

**장점**
- 더 균형 잡힌 결론
- 다양한 관점 확보
- 신뢰도 향상

**단점**
- API 호출 비용 증가
- 처리 시간 증가

---

## 핵심 정리

| 기법 | 적용 상황 | 핵심 |
|------|----------|------|
| K-shot | 특정 형식/패턴 필요 | 예시를 보여줘라 |
| CoT | 복잡한 추론 필요 | 단계별로 생각하게 해라 |
| Self-Consistency | 높은 신뢰도 필요 | 여러 번 시도하고 종합해라 |

---

## 실습 시간

Web UI를 사용하여 각 기법을 직접 실습해봅시다.

---

## 참고 자료

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Chain-of-Thought Prompting 논문](https://arxiv.org/abs/2201.11903)
- [Self-Consistency 논문](https://arxiv.org/abs/2203.11171)
