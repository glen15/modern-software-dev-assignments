"""
Prompting Basics - Gradio Web UI
AWS Bedrockë¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŒ… ê¸°ë²• ì‹¤ìŠµ
"""

import os
import re
import json
import time
from collections import Counter

import boto3
import gradio as gr
from dotenv import load_dotenv

load_dotenv()

# Bedrock client setup
bedrock = boto3.client(
    "bedrock-runtime",
    region_name=os.environ.get("AWS_REGION", "us-east-1"),
)

MODEL_ID = "anthropic.claude-3-haiku-20240307-v1:0"

# í”„ë¡¬í”„íŒ… ì˜ˆì œ ì •ì˜
EXAMPLES = {
    "k_shot": {
        "name": "K-shot Prompting",
        "description": "ì˜ˆì‹œë¥¼ ë³´ì—¬ì£¼ê³  íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ë°•ì§€ë¯¼(28ì„¸)ì€ Aì‚¬ì—ì„œ ì†”ë£¨ì…˜ì¦ˆ ì•„í‚¤í…íŠ¸(SA)ë¡œ 3ë…„ì§¸ ê·¼ë¬´ ì¤‘ì…ë‹ˆë‹¤. ì£¼ë¡œ AWSì™€ Terraformì„ ì‚¬ìš©í•˜ë©°, ìµœê·¼ì—ëŠ” ë©€í‹° í´ë¼ìš°ë“œ ì „í™˜ í”„ë¡œì íŠ¸ë¥¼ ë¦¬ë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—°ë´‰ì€ 8ì²œë§Œì›ì´ê³ , ì¬íƒê·¼ë¬´ë¥¼ ì£¼ 2íšŒ í•©ë‹ˆë‹¤.""",
        "expected": "",
        "temperature": 0.3,
        "hint": """ë‹¤ìŒ ì˜ˆì‹œë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë³µì‚¬í•´ë³´ì„¸ìš”:

ì…ë ¥: ê¹€ì² ìˆ˜(32ì„¸)ëŠ” Bì‚¬ì—ì„œ ì†”ë£¨ì…˜ì¦ˆ ì•„í‚¤í…íŠ¸(SA)ë¡œ 5ë…„ì§¸ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. Azureì™€ Kubernetes ì „ë¬¸ê°€ì´ë©°, í˜„ì¬ í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒ€ì„ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤. ì—°ë´‰ì€ 1ì–µì›ì´ê³ , í’€ ì¬íƒê·¼ë¬´ì…ë‹ˆë‹¤.
ì¶œë ¥:
[ê¸°ë³¸ì •ë³´]
- ì´ë¦„: ê¹€ì² ìˆ˜
- ë‚˜ì´: 32ì„¸
- ê²½ë ¥: 5ë…„

[íšŒì‚¬ì •ë³´]
- íšŒì‚¬: Bì‚¬
- ì§ë¬´: ì†”ë£¨ì…˜ì¦ˆ ì•„í‚¤í…íŠ¸(SA)
- ì—­í• : í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒ€ ë¦¬ë“œ

[ê¸°ìˆ ìŠ¤íƒ]
- Azure, Kubernetes

[ê·¼ë¬´ì¡°ê±´]
- ì—°ë´‰: 1ì–µì›
- ì¬íƒ: í’€ ì¬íƒê·¼ë¬´""",
    },
    "chain_of_thought": {
        "name": "Chain of Thought",
        "description": "ë‹¨ê³„ë³„ë¡œ ì¶”ë¡ í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

ì˜í¬ëŠ” 3ì¼ê°„ ìì „ê±° ì—¬í–‰ì„ í–ˆìŠµë‹ˆë‹¤.
- ì²«ì§¸ ë‚ : ì´ 60kmë¥¼ ì´ë™í–ˆê³ , ì¶œë°œ í›„ 20km ì§€ì ê³¼ ë„ì°© 15km ì „ì— íœ´ì‹ì„ ì·¨í–ˆìŠµë‹ˆë‹¤.
- ë‘˜ì§¸ ë‚ : ì²«ì§¸ ë‚ ë³´ë‹¤ 15km ë” ì´ë™í–ˆìŠµë‹ˆë‹¤.
- ì…‹ì§¸ ë‚ : ë‘˜ì§¸ ë‚  ì´ë™ ê±°ë¦¬ì˜ ì ˆë°˜ë§Œ ì´ë™í–ˆìŠµë‹ˆë‹¤.

ì§ˆë¬¸: 3ì¼ê°„ ì´ ì´ë™ ê±°ë¦¬ì—ì„œ ì²«ì§¸ ë‚  ë‘ íœ´ì‹ ì§€ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë¹¼ë©´ ì–¼ë§ˆì¸ê°€ìš”?""",
        "expected": "ì •ë‹µ: 147.5",
        "temperature": 0.3,
        "hint": """ë‹¤ìŒì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë³µì‚¬í•´ë³´ì„¸ìš”:

ë¬¸ì œë¥¼ í’€ ë•Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:
1. ì²«ì§¸ ë‚  ì´ë™ ê±°ë¦¬ì™€ ë‘ íœ´ì‹ ì§€ì  ì‚¬ì´ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì„¸ìš”
2. ë‘˜ì§¸ ë‚  ì´ë™ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì„¸ìš”
3. ì…‹ì§¸ ë‚  ì´ë™ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì„¸ìš”
4. 3ì¼ê°„ ì´ ì´ë™ ê±°ë¦¬ë¥¼ êµ¬í•˜ì„¸ìš”
5. ìµœì¢… ë‹µì„ ê³„ì‚°í•˜ì„¸ìš”

ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ ìƒê°í•´ë³´ì„¸ìš”. Let's think step by step.""",
    },
    "self_consistency": {
        "name": "Self-Consistency",
        "description": "ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‹ ë¢°ë„ ë†’ì€ ë‹µì„ ë„ì¶œí•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ë‹¤ìŒ ìŠ¤íƒ€íŠ¸ì—… ì•„ì´ë””ì–´ì˜ ì„±ê³µ ê°€ëŠ¥ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

ì•„ì´ë””ì–´: AIë¥¼ í™œìš©í•œ ë°˜ë ¤ë™ë¬¼ ê±´ê°• ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
- ìŠ¤ë§ˆíŠ¸ ëª©ê±¸ì´ë¡œ ë°˜ë ¤ë™ë¬¼ì˜ í™œë™ëŸ‰, ì‹¬ë°•ìˆ˜, ìˆ˜ë©´ íŒ¨í„´ì„ ì¸¡ì •
- AIê°€ ì´ìƒ ì§•í›„ë¥¼ ê°ì§€í•˜ë©´ ë³´í˜¸ìì—ê²Œ ì•Œë¦¼
- ì›” êµ¬ë…ë£Œ 15,000ì›
- íƒ€ê²Ÿ: ë°˜ë ¤ë™ë¬¼ ì–‘ìœ¡ ê°€êµ¬ (êµ­ë‚´ ì•½ 600ë§Œ ê°€êµ¬)

ì¥ì , ë‹¨ì , ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•˜ê³  ì„±ê³µ ê°€ëŠ¥ì„±ì„ "ìƒ/ì¤‘/í•˜"ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.""",
        "expected": "",
        "temperature": 1.0,
        "hint": """Self-ConsistencyëŠ” ë™ì¼í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

ì£¼ê´€ì  íŒë‹¨ì´ í•„ìš”í•œ ë¬¸ì œì—ì„œ AIë„ ë§¤ë²ˆ ë‹¤ë¥¸ ê´€ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ë©´ ë” ê· í˜•ì¡íŒ íŒë‹¨ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:
ìŠ¤íƒ€íŠ¸ì—… ì•„ì´ë””ì–´ë¥¼ í‰ê°€í•  ë•Œ ë‹¤ìŒì„ ë¶„ì„í•˜ì„¸ìš”:
1. ì¥ì  (2-3ê°€ì§€)
2. ë‹¨ì  (2-3ê°€ì§€)
3. ì£¼ìš” ë¦¬ìŠ¤í¬
4. ì„±ê³µ ê°€ëŠ¥ì„± (ìƒ/ì¤‘/í•˜)

ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.""",
    },
}


def call_bedrock(system_prompt: str, user_prompt: str, temperature: float = 0.5) -> str:
    """Call Bedrock Claude model and return the response text."""
    body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 2048,
        "temperature": temperature,
        "messages": [{"role": "user", "content": user_prompt}],
    }
    if system_prompt:
        body["system"] = system_prompt

    response = bedrock.invoke_model(
        modelId=MODEL_ID,
        body=json.dumps(body),
    )
    response_body = json.loads(response["body"].read())
    return response_body["content"][0]["text"]


def extract_final_answer(text: str) -> str:
    """Extract the final answer from response text."""
    # í•œê¸€ "ì •ë‹µ:" íŒ¨í„´ ë¨¼ì € ì‹œë„
    matches = re.findall(r"(?mi)^\s*ì •ë‹µ\s*:\s*(.+)\s*$", text)
    if matches:
        value = matches[-1].strip()
        num_match = re.search(r"-?\d+(?:\.\d+)?", value.replace(",", ""))
        if num_match:
            return f"ì •ë‹µ: {num_match.group(0)}"
        return f"ì •ë‹µ: {value}"

    # ì˜ì–´ "Answer:" íŒ¨í„´
    matches = re.findall(r"(?mi)^\s*answer\s*:\s*(.+)\s*$", text)
    if matches:
        value = matches[-1].strip()
        num_match = re.search(r"-?\d+(?:\.\d+)?", value.replace(",", ""))
        if num_match:
            return f"ì •ë‹µ: {num_match.group(0)}"
        return f"ì •ë‹µ: {value}"

    # "ìƒ", "ì¤‘", "í•˜" íŒ¨í„´ (Self-Consistencyìš©)
    text_lower = text.strip()
    if re.search(r'\bìƒ\b', text_lower):
        return "ìƒ"
    if re.search(r'\bì¤‘\b', text_lower):
        return "ì¤‘"
    if re.search(r'\bí•˜\b', text_lower):
        return "í•˜"

    return text.strip()[:50]  # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°


def run_single(example_key: str, system_prompt: str) -> tuple[str, str]:
    """ë‹¨ì¼ ì‹¤í–‰ - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ì´/ìˆì´ ë¹„êµ"""
    example = EXAMPLES[example_key]

    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‹¤í–‰
        start_time = time.time()
        output_without = call_bedrock("", example["user_prompt"], example["temperature"])
        time_without = time.time() - start_time

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©í•´ì„œ ì‹¤í–‰
        start_time = time.time()
        output_with = call_bedrock(system_prompt, example["user_prompt"], example["temperature"])
        time_with = time.time() - start_time

        result_without = f"â±ï¸ {time_without:.1f}ì´ˆ\n\n{output_without}"
        result_with = f"â±ï¸ {time_with:.1f}ì´ˆ\n\n{output_with}"

        return result_without, result_with

    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


def run_multiple(example_key: str, system_prompt: str, num_runs: int) -> tuple[str, str]:
    """ë‹¤ì¤‘ ì‹¤í–‰ (Self-Consistencyìš©) - ê²°ê³¼ ì¢…í•© ë¶„ì„"""
    example = EXAMPLES[example_key]

    try:
        results = []
        full_responses = []
        total_start = time.time()

        for i in range(int(num_runs)):
            start_time = time.time()
            output = call_bedrock(system_prompt, example["user_prompt"], example["temperature"])
            elapsed = time.time() - start_time

            results.append(f"--- ë¶„ì„ {i+1} ({elapsed:.1f}ì´ˆ) ---\n{output}")
            full_responses.append(f"ë¶„ì„ {i+1}: {output}")

        # ì¢…í•© ë¶„ì„ ìš”ì²­
        synthesis_prompt = f"""ë‹¤ìŒì€ ë™ì¼í•œ ìŠ¤íƒ€íŠ¸ì—… ì•„ì´ë””ì–´ì— ëŒ€í•œ {num_runs}ê°œì˜ ë…ë¦½ì ì¸ ë¶„ì„ì…ë‹ˆë‹¤.

{chr(10).join(full_responses)}

ìœ„ ë¶„ì„ë“¤ì„ ì¢…í•©í•˜ì—¬:
1. ê³µí†µì ìœ¼ë¡œ ì–¸ê¸‰ëœ ì¥ì 
2. ê³µí†µì ìœ¼ë¡œ ì–¸ê¸‰ëœ ë‹¨ì /ë¦¬ìŠ¤í¬
3. ì˜ê²¬ì´ ê°ˆë¦° ë¶€ë¶„
4. ì¢…í•© í‰ê°€ (ìƒ/ì¤‘/í•˜)

ë¥¼ ì •ë¦¬í•´ì£¼ì„¸ìš”."""

        start_time = time.time()
        synthesis = call_bedrock("ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì¢…í•©í•´ì£¼ì„¸ìš”.", synthesis_prompt, 0.3)
        synthesis_time = time.time() - start_time

        total_time = time.time() - total_start
        all_results = f"â±ï¸ ì´ {total_time:.1f}ì´ˆ\n\n" + "\n\n".join(results)
        summary = f"â±ï¸ ì¢…í•© ë¶„ì„ ({synthesis_time:.1f}ì´ˆ)\n\n{synthesis}"

        return all_results, summary

    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", ""


def create_tab(example_key: str):
    """ê° í”„ë¡¬í”„íŒ… ê¸°ë²• íƒ­ ìƒì„±"""
    example = EXAMPLES[example_key]

    with gr.Column():
        gr.Markdown(f"### {example['description']}")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("**User Prompt (ë¬¸ì œ)**")
                gr.Textbox(value=example["user_prompt"], lines=8, interactive=False, label="")
                with gr.Accordion("ğŸ’¡ íŒíŠ¸ ë³´ê¸° (ì§ì ‘ ì‹œë„í•´ë³¸ í›„ ì—´ì–´ë³´ì„¸ìš”)", open=False):
                    gr.Textbox(value=example["hint"], lines=15, interactive=True, label="íŒíŠ¸ (ë³µì‚¬í•´ì„œ ìœ„ System Promptì— ë¶™ì—¬ë„£ê¸°)")

            with gr.Column(scale=1):
                system_prompt = gr.Textbox(
                    label="System Prompt (ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì„ ì ìš©í•˜ì„¸ìš”)",
                    lines=12,
                    placeholder="í”„ë¡¬í”„íŒ… ê¸°ë²•ì„ ì ìš©í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                )

        with gr.Row():
            run_btn = gr.Button("ì‹¤í–‰", variant="primary")
            if example_key == "self_consistency":
                num_runs = gr.Slider(minimum=3, maximum=10, value=5, step=1, label="ì‹¤í–‰ íšŸìˆ˜")

        if example_key == "self_consistency":
            with gr.Row():
                with gr.Column():
                    output_left = gr.Textbox(label="ê° ì‹¤í–‰ ê²°ê³¼", lines=12, max_lines=12)
                with gr.Column():
                    output_right = gr.Textbox(label="ë‹¤ìˆ˜ê²° ìš”ì•½", lines=12, max_lines=12)
            run_btn.click(
                fn=lambda s, n: run_multiple(example_key, s, n),
                inputs=[system_prompt, num_runs],
                outputs=[output_left, output_right]
            )
        else:
            with gr.Row():
                with gr.Column():
                    output_left = gr.Textbox(label="ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ì´", lines=12, max_lines=12)
                with gr.Column():
                    output_right = gr.Textbox(label="ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©", lines=12, max_lines=12)
            run_btn.click(
                fn=lambda s: run_single(example_key, s),
                inputs=[system_prompt],
                outputs=[output_left, output_right]
            )


# Gradio ì•± ìƒì„±
with gr.Blocks(title="Prompting Basics", theme=gr.themes.Soft()) as app:
    gr.Markdown("""
    # Prompting Basics
    ### AWS Bedrockë¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŒ… ê¸°ë²• ì‹¤ìŠµ

    ê° íƒ­ì—ì„œ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŒ… ê¸°ë²•ì„ ì‹¤ìŠµí•´ë³´ì„¸ìš”. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì ì ˆí•œ ê¸°ë²•ì„ ì ìš©í•´ë³´ì„¸ìš”.
    """)

    with gr.Tabs():
        with gr.TabItem("K-shot Prompting"):
            create_tab("k_shot")

        with gr.TabItem("Chain of Thought"):
            create_tab("chain_of_thought")

        with gr.TabItem("Self-Consistency"):
            create_tab("self_consistency")


if __name__ == "__main__":
    app.launch()
