"""
Prompting Basics - Streamlit Web UI
AWS Bedrockë¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŒ… ê¸°ë²• ì‹¤ìŠµ
"""

import os
import re
import json
from collections import Counter

import boto3
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

# Bedrock client setup
@st.cache_resource
def get_bedrock_client():
    return boto3.client(
        "bedrock-runtime",
        region_name=os.environ.get("AWS_REGION", "us-east-1"),
    )

bedrock = get_bedrock_client()

MODEL_ID = os.environ.get("BEDROCK_MODEL_ID", "amazon.nova-lite-v1:0")

# í”„ë¡¬í”„íŒ… ì˜ˆì œ ì •ì˜
EXAMPLES = {
    "K-shot Prompting": {
        "key": "k_shot",
        "description": "ì˜ˆì‹œë¥¼ ë³´ì—¬ì£¼ê³  íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ë°•ì§€ë¯¼(28ì„¸)ì€ ì¹´ì¹´ì˜¤ì—ì„œ ë°±ì—”ë“œ ê°œë°œìë¡œ 3ë…„ì§¸ ê·¼ë¬´ ì¤‘ì…ë‹ˆë‹¤.""",
        "expected": "ì´ë¦„: ë°•ì§€ë¯¼\në‚˜ì´: 28\níšŒì‚¬: ì¹´ì¹´ì˜¤\nì§ë¬´: ë°±ì—”ë“œ ê°œë°œì\nê²½ë ¥: 3ë…„",
        "temperature": 0.3,
        "hint": """ì˜ˆì‹œë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•´ì„œ ì¶œë ¥ í˜•ì‹ì„ ì§€ì •í•´ë³´ì„¸ìš”:

ì…ë ¥: ê¹€ì² ìˆ˜(32ì„¸)ëŠ” ë„¤ì´ë²„ì—ì„œ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œ 5ë…„ì§¸ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì¶œë ¥:
ì´ë¦„: ê¹€ì² ìˆ˜
ë‚˜ì´: 32
íšŒì‚¬: ë„¤ì´ë²„
ì§ë¬´: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì
ê²½ë ¥: 5ë…„""",
    },
    "Chain of Thought": {
        "key": "chain_of_thought",
        "description": "ë‹¨ê³„ë³„ë¡œ ì¶”ë¡ í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ì´ ë¬¸ì œë¥¼ í’€ê³ , ë§ˆì§€ë§‰ ì¤„ì— "ì •ë‹µ: <ìˆ«ì>" í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë‹µì„ ì ìœ¼ì„¸ìš”.

3ì˜ 12345ì œê³±ì„ 100ìœ¼ë¡œ ë‚˜ëˆˆ ë‚˜ë¨¸ì§€ëŠ” ì–¼ë§ˆì¸ê°€ìš”? (3^12345 mod 100)""",
        "expected": "ì •ë‹µ: 43",
        "temperature": 0.3,
        "hint": "'ë‹¨ê³„ë³„ë¡œ ìƒê°í•´ë³´ì„¸ìš”' ë˜ëŠ” 'Let's think step by step'ì„ ì¶”ê°€í•´ë³´ì„¸ìš”.",
    },
    "Self-Consistency": {
        "key": "self_consistency",
        "description": "ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ ë‹¤ìˆ˜ê²°ë¡œ ë‹µì„ ê²°ì •í•˜ëŠ” ê¸°ë²•",
        "user_prompt": """ì´ ë¬¸ì œë¥¼ í’€ê³ , ë§ˆì§€ë§‰ ì¤„ì— "ì •ë‹µ: <ìˆ«ì>" í˜•ì‹ìœ¼ë¡œ ìµœì¢… ë‹µì„ ì ìœ¼ì„¸ìš”.

ì˜í¬ëŠ” 60km ìì „ê±° ì—¬í–‰ ì¤‘ ë‘ ë²ˆ ë©ˆì·„ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” ì¶œë°œ í›„ 20km ì§€ì ì—ì„œ ë©ˆì·„ê³ ,
ë‘ ë²ˆì§¸ëŠ” ë„ì°© 15km ì „ì— ë©ˆì·„ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì •ë¥˜ì¥ê³¼ ë‘ ë²ˆì§¸ ì •ë¥˜ì¥ ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ëª‡ kmì¸ê°€ìš”?""",
        "expected": "ì •ë‹µ: 25",
        "temperature": 1.0,
        "hint": "ë†’ì€ temperatureë¡œ ë‹¤ì–‘í•œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ë‹¤ìˆ˜ê²°ë¡œ ê²°ì •í•©ë‹ˆë‹¤.",
    },
}


def call_bedrock(system_prompt: str, user_prompt: str, temperature: float = 0.5) -> str:
    """Call Bedrock Nova model and return the response text."""
    messages = [{"role": "user", "content": [{"text": user_prompt}]}]

    body = {
        "messages": messages,
        "inferenceConfig": {
            "temperature": temperature,
            "maxTokens": 2048,
        },
    }

    if system_prompt:
        body["system"] = [{"text": system_prompt}]

    response = bedrock.invoke_model(
        modelId=MODEL_ID,
        body=json.dumps(body),
    )

    response_body = json.loads(response["body"].read())
    return response_body["output"]["message"]["content"][0]["text"]


def extract_final_answer(text: str) -> str:
    """Extract the final 'ì •ë‹µ: ...' or 'Answer: ...' line from a verbose reasoning trace."""
    # í•œê¸€ "ì •ë‹µ:" íŒ¨í„´ ë¨¼ì € ì‹œë„
    matches = re.findall(r"(?mi)^\s*ì •ë‹µ\s*:\s*(.+)\s*$", text)
    if matches:
        value = matches[-1].strip()
        num_match = re.search(r"-?\d+(?:\.\d+)?", value.replace(",", ""))
        if num_match:
            return f"ì •ë‹µ: {num_match.group(0)}"
        return f"ì •ë‹µ: {value}"

    # ì˜ì–´ "Answer:" íŒ¨í„´
    matches = re.findall(r"(?mi)^\s*answer\s*:\s*(.+)\s*$", text)
    if matches:
        value = matches[-1].strip()
        num_match = re.search(r"-?\d+(?:\.\d+)?", value.replace(",", ""))
        if num_match:
            return f"ì •ë‹µ: {num_match.group(0)}"
        return f"ì •ë‹µ: {value}"
    return text.strip()


# Streamlit ì•± ì‹œì‘
st.set_page_config(page_title="Prompting Basics", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– Prompting Basics")
st.markdown("### AWS Bedrockë¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŒ… ê¸°ë²• ì‹¤ìŠµ")
st.caption(f"ì‚¬ìš© ëª¨ë¸: `{MODEL_ID}`")

# íƒ­ ìƒì„±
tabs = st.tabs(list(EXAMPLES.keys()))

for tab, (name, example) in zip(tabs, EXAMPLES.items()):
    with tab:
        st.markdown(f"**{example['description']}**")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("##### User Prompt (ë¬¸ì œ)")
            st.code(example["user_prompt"], language=None)
            st.info(f"ğŸ’¡ **íŒíŠ¸:** {example['hint']}")

        with col2:
            st.markdown("##### System Prompt")
            system_prompt = st.text_area(
                "í”„ë¡¬í”„íŒ… ê¸°ë²•ì„ ì ìš©í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                key=f"system_prompt_{example['key']}",
                height=150,
                placeholder="ì—¬ê¸°ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
            )

            if example["key"] == "self_consistency":
                num_runs = st.slider("ì‹¤í–‰ íšŸìˆ˜", min_value=3, max_value=10, value=5, key=f"num_runs_{example['key']}")

            run_btn = st.button("â–¶ï¸ ì‹¤í–‰", key=f"run_{example['key']}", type="primary", use_container_width=True)

        st.divider()

        # ê²°ê³¼ í‘œì‹œ ì˜ì—­
        if run_btn:
            if example["key"] == "self_consistency":
                # ë‹¤ì¤‘ ì‹¤í–‰
                results = []
                answers = []

                progress_bar = st.progress(0)
                status_text = st.empty()

                for i in range(num_runs):
                    status_text.text(f"ì‹¤í–‰ ì¤‘... ({i+1}/{num_runs})")
                    progress_bar.progress((i + 1) / num_runs)

                    try:
                        output = call_bedrock(system_prompt, example["user_prompt"], example["temperature"])
                        final_answer = extract_final_answer(output)
                        results.append({"run": i + 1, "output": output, "answer": final_answer})
                        answers.append(final_answer.strip())
                    except Exception as e:
                        st.error(f"ì‹¤í–‰ {i+1} ì˜¤ë¥˜: {str(e)}")

                progress_bar.empty()
                status_text.empty()

                if answers:
                    counts = Counter(answers)
                    majority_answer, majority_count = counts.most_common(1)[0]

                    col_result1, col_result2 = st.columns([1, 2])

                    with col_result1:
                        st.metric("ë‹¤ìˆ˜ê²° ê²°ê³¼", majority_answer, f"{majority_count}/{num_runs}")

                        st.markdown("**ë‹µë³€ ë¶„í¬:**")
                        for ans, cnt in counts.most_common():
                            st.write(f"- `{ans}`: {cnt}íšŒ")

                    with col_result2:
                        with st.expander("ìƒì„¸ ê²°ê³¼ ë³´ê¸°", expanded=True):
                            for r in results:
                                st.markdown(f"**ì‹¤í–‰ {r['run']}** - ì¶”ì¶œëœ ë‹µ: `{r['answer']}`")
                                st.code(r["output"], language=None)
                                st.divider()

            else:
                # ë‹¨ì¼ ì‹¤í–‰
                with st.spinner("ì‹¤í–‰ ì¤‘..."):
                    try:
                        output = call_bedrock(system_prompt, example["user_prompt"], example["temperature"])

                        if "ì •ë‹µ:" in example["expected"] or "Answer:" in example["expected"]:
                            final_answer = extract_final_answer(output)
                        else:
                            final_answer = output.strip()

                        col_result1, col_result2 = st.columns([1, 2])

                        with col_result1:
                            st.metric("ì¶”ì¶œëœ ê²°ê³¼", final_answer)

                        with col_result2:
                            st.markdown("**ëª¨ë¸ ì¶œë ¥:**")
                            st.code(output, language=None)

                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
